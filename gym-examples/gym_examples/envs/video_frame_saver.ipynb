{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6ca89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oadam/flight_success_1700steps_20250829_105910.mp4\n",
      "Saved frame at 33s as frame_33s.png\n",
      "Saved frame at 66s as frame_66s.png\n",
      "Saved frame at 100s as frame_100s.png\n",
      "Saved frame at 133s as frame_133s.png\n",
      "Saved frame at 166s as frame_166s.png\n",
      "Frame extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your video file\n",
    "downloads_path = os.path.expanduser(\"~\")\n",
    "video_path = os.path.join(downloads_path, \"flight_success_1700steps_20250829_105910.mp4\")\n",
    "print(video_path)\n",
    "\n",
    "# Updated time stamps in seconds - now including 1:22\n",
    "timestamps = [33, 66, 100, 133, 166]  # 0:33, 1:06, 1:40, 2:13, 2:46\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Extract and save frames\n",
    "for i, timestamp in enumerate(timestamps):\n",
    "    # Set video position to timestamp\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)\n",
    "    \n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save frame as PNG\n",
    "        output_filename = f\"frame_{timestamp}s.png\"\n",
    "        output_path = os.path.join(downloads_path, output_filename)\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(f\"Saved frame at {timestamp}s as {output_filename}\")\n",
    "    else:\n",
    "        print(f\"Could not extract frame at {timestamp}s\")\n",
    "\n",
    "cap.release()\n",
    "print(\"Frame extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bffe355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded frame at 33s\n",
      "Loaded frame at 66s\n",
      "Loaded frame at 100s\n",
      "Loaded frame at 133s\n",
      "Loaded frame at 166s\n",
      "Cropping all frames to: top=182, bottom=1833, left=422, right=1969\n",
      "Cropped composite image saved as: video_frames_composite_cropped.png\n",
      "Composite dimensions: 7735x1651\n",
      "Each frame cropped to: 1547x1651\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def find_content_bounds(image):\n",
    "    \"\"\"Find the bounding box of non-white content in the image\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find non-white pixels (threshold at 250 to catch near-white pixels too)\n",
    "    non_white = gray < 250\n",
    "    \n",
    "    # Find bounding box\n",
    "    rows = np.any(non_white, axis=1)\n",
    "    cols = np.any(non_white, axis=0)\n",
    "    \n",
    "    if not np.any(rows) or not np.any(cols):\n",
    "        return None\n",
    "    \n",
    "    top, bottom = np.where(rows)[0][[0, -1]]\n",
    "    left, right = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    return top, bottom, left, right\n",
    "\n",
    "# Path setup\n",
    "downloads_path = os.path.expanduser(\"~\")\n",
    "timestamps = [33, 66, 100, 133, 166]  # 0:33, 1:06, 1:40, 2:13, 2:46\n",
    "\n",
    "# Load all frames and find common crop bounds\n",
    "frames = []\n",
    "all_bounds = []\n",
    "\n",
    "for timestamp in timestamps:\n",
    "    frame_path = os.path.join(downloads_path, f\"frame_{timestamp}s.png\")  # Load PNG files\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is not None:\n",
    "        frames.append(frame)\n",
    "        bounds = find_content_bounds(frame)\n",
    "        if bounds:\n",
    "            all_bounds.append(bounds)\n",
    "        print(f\"Loaded frame at {timestamp}s\")\n",
    "    else:\n",
    "        print(f\"Could not load frame at {timestamp}s\")\n",
    "\n",
    "if len(frames) == 5 and len(all_bounds) == 5:\n",
    "    # Find the common crop area (union of all content areas with some padding)\n",
    "    top = min(bound[0] for bound in all_bounds) - 10  # Add some padding\n",
    "    bottom = max(bound[1] for bound in all_bounds) + 10\n",
    "    left = min(bound[2] for bound in all_bounds) - 10\n",
    "    right = max(bound[3] for bound in all_bounds) + 10\n",
    "    \n",
    "    # Ensure bounds are within image dimensions\n",
    "    top = max(0, top)\n",
    "    left = max(0, left)\n",
    "    bottom = min(frames[0].shape[0], bottom)\n",
    "    right = min(frames[0].shape[1], right)\n",
    "    \n",
    "    print(f\"Cropping all frames to: top={top}, bottom={bottom}, left={left}, right={right}\")\n",
    "    \n",
    "    # Crop all frames to the same area\n",
    "    cropped_frames = []\n",
    "    for frame in frames:\n",
    "        cropped = frame[top:bottom, left:right]\n",
    "        cropped_frames.append(cropped)\n",
    "    \n",
    "    # Concatenate frames horizontally (directly side by side)\n",
    "    composite_image = np.hstack(cropped_frames)\n",
    "    \n",
    "    # Save composite image as PNG\n",
    "    composite_path = os.path.join(downloads_path, \"video_frames_composite_cropped.png\")\n",
    "    cv2.imwrite(composite_path, composite_image)\n",
    "    print(f\"Cropped composite image saved as: video_frames_composite_cropped.png\")\n",
    "    print(f\"Composite dimensions: {composite_image.shape[1]}x{composite_image.shape[0]}\")\n",
    "    print(f\"Each frame cropped to: {cropped_frames[0].shape[1]}x{cropped_frames[0].shape[0]}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Expected 5 frames, but loaded {len(frames)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18a9e488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oadam/flight_success_1700steps_20250829_105910.mp4\n",
      "Saved frame at 33s as frame_33s.png\n",
      "Saved frame at 66s as frame_66s.png\n",
      "Saved frame at 100s as frame_100s.png\n",
      "Saved frame at 133s as frame_133s.png\n",
      "Saved frame at 166s as frame_166s.png\n",
      "Frame extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your video file\n",
    "downloads_path = os.path.expanduser(\"~\")\n",
    "video_path = os.path.join(downloads_path, \"flight_success_1700steps_20250829_105910.mp4\")\n",
    "print(video_path)\n",
    "\n",
    "# Updated time stamps for 5 frames: 33s to 2:46\n",
    "timestamps = [33, 66, 100, 133, 166]  # 0:33, 1:06, 1:40, 2:13, 2:46\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Extract and save frames\n",
    "for i, timestamp in enumerate(timestamps):\n",
    "    # Set video position to timestamp\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)\n",
    "    \n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save frame as PNG\n",
    "        output_filename = f\"frame_{timestamp}s.png\"\n",
    "        output_path = os.path.join(downloads_path, output_filename)\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(f\"Saved frame at {timestamp}s as {output_filename}\")\n",
    "    else:\n",
    "        print(f\"Could not extract frame at {timestamp}s\")\n",
    "\n",
    "cap.release()\n",
    "print(\"Frame extraction complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15273870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded frame at 33s\n",
      "Loaded frame at 66s\n",
      "Loaded frame at 100s\n",
      "Loaded frame at 133s\n",
      "Loaded frame at 166s\n",
      "Step 1 - Removing whitespace\n",
      "Step 2 - Removing axes/title\n",
      "Final composite image saved as: video_frames_composite_final.png\n",
      "Composite dimensions: 7040x1466\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def find_content_bounds(image):\n",
    "    \"\"\"Find the bounding box of non-white content in the image (removes whitespace)\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    non_white = gray < 250\n",
    "    rows = np.any(non_white, axis=1)\n",
    "    cols = np.any(non_white, axis=0)\n",
    "    \n",
    "    if not np.any(rows) or not np.any(cols):\n",
    "        return None\n",
    "    \n",
    "    top, bottom = np.where(rows)[0][[0, -1]]\n",
    "    left, right = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    return top, bottom, left, right\n",
    "\n",
    "def crop_axes_and_title_relaxed(image):\n",
    "    \"\"\"Remove axes and title with more conservative cropping\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    top_crop = int(height * 0.12)\n",
    "    bottom_crop = int(height * 0.96)\n",
    "    left_crop = int(width * 0.06)\n",
    "    right_crop = int(width * 0.97)\n",
    "    \n",
    "    return top_crop, bottom_crop, left_crop, right_crop\n",
    "\n",
    "# Path setup\n",
    "downloads_path = os.path.expanduser(\"~\")\n",
    "timestamps = [33, 66, 100, 133, 166]\n",
    "\n",
    "# Load all frames\n",
    "frames = []\n",
    "all_bounds = []\n",
    "\n",
    "for timestamp in timestamps:\n",
    "    frame_path = os.path.join(downloads_path, f\"frame_{timestamp}s.png\")\n",
    "    frame = cv2.imread(frame_path)\n",
    "    if frame is not None:\n",
    "        frames.append(frame)\n",
    "        bounds = find_content_bounds(frame)\n",
    "        if bounds:\n",
    "            all_bounds.append(bounds)\n",
    "        print(f\"Loaded frame at {timestamp}s\")\n",
    "    else:\n",
    "        print(f\"Could not load frame at {timestamp}s\")\n",
    "\n",
    "if len(frames) == 5 and len(all_bounds) == 5:\n",
    "    # Step 1: Find common whitespace crop area\n",
    "    top_ws = max(0, min(bound[0] for bound in all_bounds) - 10)\n",
    "    left_ws = max(0, min(bound[2] for bound in all_bounds) - 10)\n",
    "    bottom_ws = min(frames[0].shape[0], max(bound[1] for bound in all_bounds) + 10)\n",
    "    right_ws = min(frames[0].shape[1], max(bound[3] for bound in all_bounds) + 10)\n",
    "    \n",
    "    print(f\"Step 1 - Removing whitespace\")\n",
    "    \n",
    "    # Step 2: Remove whitespace from all frames\n",
    "    whitespace_cropped_frames = [frame[top_ws:bottom_ws, left_ws:right_ws] for frame in frames]\n",
    "    \n",
    "    # Step 3: Remove axes and title\n",
    "    top_ax, bottom_ax, left_ax, right_ax = crop_axes_and_title_relaxed(whitespace_cropped_frames[0])\n",
    "    \n",
    "    print(f\"Step 2 - Removing axes/title\")\n",
    "    \n",
    "    # Step 4: Apply cropping to all frames\n",
    "    final_cropped_frames = [frame[top_ax:bottom_ax, left_ax:right_ax] for frame in whitespace_cropped_frames]\n",
    "    \n",
    "    # Step 5: Add new title text matching matplotlib style\n",
    "    titled_frames = []\n",
    "    for i, frame in enumerate(final_cropped_frames):\n",
    "        # Add white space at the top for title\n",
    "        title_height = 80\n",
    "        titled_frame = np.ones((frame.shape[0] + title_height, frame.shape[1], 3), dtype=np.uint8) * 255\n",
    "        titled_frame[title_height:, :] = frame\n",
    "        \n",
    "        # Calculate step number\n",
    "        timestamp = timestamps[i]\n",
    "        step_number = timestamp * 10\n",
    "        title_text = f\"UAM Simulation - Step {step_number}.0\"\n",
    "        \n",
    "        # Font settings to match matplotlib fontsize=16, fontweight='bold'\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX  # Cleaner font, closer to matplotlib\n",
    "        font_scale = 2  # Adjusted to match fontsize=16\n",
    "        font_thickness = 3  # Bold weight\n",
    "        font_color = (0, 0, 0)  # Black text\n",
    "        \n",
    "        # Calculate text size and position for centering\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(title_text, font, font_scale, font_thickness)\n",
    "        text_x = (titled_frame.shape[1] - text_width) // 2\n",
    "        text_y = (title_height + text_height) // 2\n",
    "        \n",
    "        # Add text\n",
    "        cv2.putText(titled_frame, title_text, (text_x, text_y), \n",
    "                   font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n",
    "        \n",
    "        titled_frames.append(titled_frame)\n",
    "    \n",
    "    # Step 6: Concatenate frames horizontally\n",
    "    composite_image = np.hstack(titled_frames)\n",
    "    \n",
    "    # Save composite image\n",
    "    composite_path = os.path.join(downloads_path, \"video_frames_composite_final.png\")\n",
    "    cv2.imwrite(composite_path, composite_image)\n",
    "    print(f\"Final composite image saved as: video_frames_composite_final.png\")\n",
    "    print(f\"Composite dimensions: {composite_image.shape[1]}x{composite_image.shape[0]}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Expected 5 frames, but loaded {len(frames)} frames\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAM_AMOD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
